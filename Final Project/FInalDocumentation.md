## Final Project Documentation.



# Start/Struggles

Without having any knowledge to live coding nor javascript, I started looking up on Hydra's github page.
I first played with simple visual oscillators changing different variables for different effects.
Initiate Cam, Screen, trying different sources
Then I try to find out how to make it sonically interactive, and I found a term called FFT function(frequency domain information)
I realize the range of analyzing the sound is very narrow.


# Visual Feedback

https://www.youtube.com/watch?v=m-Q7b82Y9Mk
followed what he was explaining for feedback technique.

>> .rotate(() => Math.PI * mouse.x /180)
- Mahalia H-R

src(o0).modulateHue(src(o0).scale(1.02),1)
>> .layer(src(o1).luma(0.1,1e-20))
- Naoto Hieda


# Accomplishments, and further improvments.

I figured out how to interact with simple audio signals with adding some fun variables.
You can make noise to change the color, and move the mouse.
It would be better if the visual reactions are more lively and detailed.  
Mine is very limited.
